{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-22T13:48:06.917703Z",
     "iopub.status.busy": "2024-11-22T13:48:06.917347Z",
     "iopub.status.idle": "2024-11-22T13:48:20.434879Z",
     "shell.execute_reply": "2024-11-22T13:48:20.434038Z",
     "shell.execute_reply.started": "2024-11-22T13:48:06.91767Z"
    },
    "id": "gWM1Oi1AJ4VD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T13:48:20.43677Z",
     "iopub.status.busy": "2024-11-22T13:48:20.436259Z",
     "iopub.status.idle": "2024-11-22T13:48:20.987938Z",
     "shell.execute_reply": "2024-11-22T13:48:20.987094Z",
     "shell.execute_reply.started": "2024-11-22T13:48:20.436741Z"
    },
    "id": "P2CArfFuJ4VE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/saruo/Downloads/archive/PoetryFoundationData.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T13:48:20.989251Z",
     "iopub.status.busy": "2024-11-22T13:48:20.988971Z",
     "iopub.status.idle": "2024-11-22T13:48:20.993597Z",
     "shell.execute_reply": "2024-11-22T13:48:20.992641Z",
     "shell.execute_reply.started": "2024-11-22T13:48:20.98922Z"
    },
    "id": "5fgcSD8WJ4VF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "poem = df['Poem'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T13:48:20.994949Z",
     "iopub.status.busy": "2024-11-22T13:48:20.994632Z",
     "iopub.status.idle": "2024-11-22T13:48:21.003432Z",
     "shell.execute_reply": "2024-11-22T13:48:21.002581Z",
     "shell.execute_reply.started": "2024-11-22T13:48:20.994925Z"
    },
    "id": "A17NzX-IJ4VF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_notations(poem):\n",
    "  return re.sub(r'[\\n\\r]', '', poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T13:48:21.005765Z",
     "iopub.status.busy": "2024-11-22T13:48:21.005488Z",
     "iopub.status.idle": "2024-11-22T13:48:21.015372Z",
     "shell.execute_reply": "2024-11-22T13:48:21.014584Z",
     "shell.execute_reply.started": "2024-11-22T13:48:21.00574Z"
    },
    "id": "cBAI2Iw4J4VG",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuations(poem):\n",
    "  return re.sub(r'[^\\w\\s]', '', poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T13:48:21.016451Z",
     "iopub.status.busy": "2024-11-22T13:48:21.016212Z",
     "iopub.status.idle": "2024-11-22T13:48:21.024597Z",
     "shell.execute_reply": "2024-11-22T13:48:21.023647Z",
     "shell.execute_reply.started": "2024-11-22T13:48:21.016428Z"
    },
    "id": "arPi17z4J4VH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_digits(poem):\n",
    "  return re.sub(r'\\d', '', poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T13:48:21.025755Z",
     "iopub.status.busy": "2024-11-22T13:48:21.025478Z",
     "iopub.status.idle": "2024-11-22T13:48:21.034713Z",
     "shell.execute_reply": "2024-11-22T13:48:21.033971Z",
     "shell.execute_reply.started": "2024-11-22T13:48:21.025731Z"
    },
    "id": "T2eB_tSZJ4VH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(poem):\n",
    "    poem = remove_notations(poem)\n",
    "    poem = remove_punctuations(poem)\n",
    "    poem = remove_digits(poem)\n",
    "    return poem.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T13:48:21.036307Z",
     "iopub.status.busy": "2024-11-22T13:48:21.03572Z",
     "iopub.status.idle": "2024-11-22T13:48:21.045377Z",
     "shell.execute_reply": "2024-11-22T13:48:21.044606Z",
     "shell.execute_reply.started": "2024-11-22T13:48:21.03627Z"
    },
    "id": "AZOjNECaJ4VJ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_list(poems):\n",
    "    return [preprocessing(poem) for poem in poems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T13:48:21.047314Z",
     "iopub.status.busy": "2024-11-22T13:48:21.046507Z",
     "iopub.status.idle": "2024-11-22T13:48:22.048308Z",
     "shell.execute_reply": "2024-11-22T13:48:22.047626Z",
     "shell.execute_reply.started": "2024-11-22T13:48:21.047277Z"
    },
    "id": "UBcONNzOJ4VJ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "poem_list = preprocess_list(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T13:48:22.049798Z",
     "iopub.status.busy": "2024-11-22T13:48:22.049423Z",
     "iopub.status.idle": "2024-11-22T13:48:22.111659Z",
     "shell.execute_reply": "2024-11-22T13:48:22.110351Z",
     "shell.execute_reply.started": "2024-11-22T13:48:22.049761Z"
    },
    "id": "BLkZUtfAJ4VK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "poem_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T13:48:22.113405Z",
     "iopub.status.busy": "2024-11-22T13:48:22.113134Z",
     "iopub.status.idle": "2024-11-22T13:49:10.183005Z",
     "shell.execute_reply": "2024-11-22T13:49:10.182275Z",
     "shell.execute_reply.started": "2024-11-22T13:48:22.113381Z"
    },
    "id": "j5F5Dh5_J4VK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenize = Tokenizer()\n",
    "tokenize.fit_on_texts(poem_list)\n",
    "total_words = len(tokenize.word_index) + 1\n",
    "input_seq = []\n",
    "for i in poem_list:\n",
    "    token_list = tokenize.texts_to_sequences([i])[0]\n",
    "    for j in range(1, len(token_list)):\n",
    "        n_gram = token_list[:j+1]\n",
    "        input_seq.append(n_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T13:49:10.184229Z",
     "iopub.status.busy": "2024-11-22T13:49:10.183987Z",
     "iopub.status.idle": "2024-11-22T13:49:10.190666Z",
     "shell.execute_reply": "2024-11-22T13:49:10.189778Z",
     "shell.execute_reply.started": "2024-11-22T13:49:10.184205Z"
    },
    "id": "VioKy9hPJ4VK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_seq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T13:49:10.192278Z",
     "iopub.status.busy": "2024-11-22T13:49:10.191859Z",
     "iopub.status.idle": "2024-11-22T13:49:10.200859Z",
     "shell.execute_reply": "2024-11-22T13:49:10.200048Z",
     "shell.execute_reply.started": "2024-11-22T13:49:10.192242Z"
    },
    "id": "90bHHYkkJ4VL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# max_sequence_len = len(max(Input, key=len))\n",
    "# Input = np.array(pad_sequences(Input, maxlen=max_sequence_len))\n",
    "# predictors = Input[:,:-1]  #selects all the columns of the Input array except for the last column\n",
    "# label = Input[:,-1] #elects only the last column of the Input array\n",
    "# label =keras.utils.to_categorical(label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T13:49:10.203574Z",
     "iopub.status.busy": "2024-11-22T13:49:10.203324Z"
    },
    "id": "dEL5klHwJ4VL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_sequence_len = len(max(input_seq, key=len))\n",
    "input_sequences = np.array(pad_sequences(input_seq, maxlen=max_sequence_len))\n",
    "\n",
    "predictors = input_sequences[:, :-1]  # All columns except the last one\n",
    "label = input_sequences[:, -1]       # Only the last column\n",
    "label = keras.utils.to_categorical(label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuXwBfM-J4VL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_len = max_sequence_len - 1\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words,300, input_length=input_len))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7m19RH4J4VL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.fit(predictors, label, epochs=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KXd31Wu0J4VP",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.fit(predictors, label, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XmQFeaZKJ4VP",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_text(model, token, max_sequence_len):\n",
    "    #seed_text = input(\"Enter some text: \")\n",
    "    #next_words = int(input(\"Enter the number of words to generate: \"))\n",
    "    seed_text = \"River river\"\n",
    "    next_words = 5\n",
    "    for _ in range(next_words):\n",
    "        token_list = token.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "\n",
    "        predicted = np.argmax(predicted_probs) + 1\n",
    "\n",
    "        output_word = \"\"\n",
    "        for word,index in token.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHLZ9i8SJ4VP",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "generated_text = generate_text(model, token, max_sequence_len)\n",
    "print(\"The generated text is : \",generated_text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LSTM - Poetry Generation",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6125138,
     "sourceId": 9958656,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
